<!DOCTYPE html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"><![endif]-->
<!--[if IE 7]><html class="no-js lt-ie9 lt-ie8" <![endif]-->
<!--[if IE 8]><html class="no-js lt-ie9" <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <title>Deep Learning (3/5): Structuring ML projects</title>

    <!-- Open Graph Meta -->
    <meta content="Dani's Braindump" property="og:site_name">
    
      <meta content="Deep Learning (3/5): Structuring ML projects" property="og:title">
    
    
      <meta content="article" property="og:type">
    
    
      <meta content="My thoughts about the world" property="og:description">
    
    
      <meta content="https://tiefenauer.github.io/ml/deep-learning/3" property="og:url">
    
    
    
      <meta content="https://tiefenauer.github.io/assets/img/header_image.jpg" property="og:image">
    

    <!-- Twitter Cards -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@danitiefenauer">
    <meta name="twitter:creator" content="@danitiefenauer">
    
      <meta name="twitter:title" content="Deep Learning (3/5): Structuring ML projects">
    
    
      <meta name="twitter:url" content="https://tiefenauer.github.io/ml/deep-learning/3">
    
    
      <meta name="twitter:description" content="My thoughts about the world">
    
    
      <meta name="twitter:image:src" content="https://tiefenauer.github.io/assets/img/header_image.jpg">
    


    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="/assets/img/favicon.ico" />

    <!-- Come and get me RSS readers -->
    <link rel="alternate" type="application/rss+xml" title="Dani's Braindump" href="https://tiefenauer.github.io/feed.xml" />

    <!-- Bootstrap: include before theme CSS so styles are overridden -->
    <!--<link rel="stylesheet" href="/assets/css/bootstrap.css">-->

    <!-- FontAwesome icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/assets/css/style.css">
    <!-- custom styles -->
    <link rel="stylesheet" href="/assets/css/custom.css">

    <!--[if IE 8]><link rel="stylesheet" href="/assets/css/ie.css"><![endif]-->
    <link rel="canonical" href="https://tiefenauer.github.io/ml/deep-learning/3">

    <!-- Modernizr -->
    <script src="/assets/js/modernizr.custom.15390.js" type="text/javascript"></script>

    <!-- Google Analytics -->

    <!-- Google Analytics: change UA-XXXXX-X to be your site's ID. -->
<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-56931568-3', 'auto');
ga('send', 'pageview');

</script>



<!-- jQuery -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src=""><\/script>')</script>
<script src="/assets/js/dropcap.min.js"></script>
<script src="/assets/js/responsive-nav.min.js"></script>
<script src="/assets/js/scripts.js"></script>

<!-- Bootstrap: http://getbootstrap.com/docs/4.1/components/alerts/ -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>


<!-- UniteGallery: http://unitegallery.net/index.php?page=documentation#changing_theme -->
<!-- Final Tiles Gallery: https://www.final-tiles-gallery.com -->
<script src="/assets/js/unitegallery/unitegallery.min.js"></script>
<script src="/assets/js/unitegallery/themes/tiles/ug-theme-tiles.js"></script>
<link rel='stylesheet' href="/assets/css/unitegallery/unite-gallery.css" type='text/css' />
<link rel='stylesheet' href="/assets/js/unitegallery/themes/default/ug-theme-default.css" type='text/css' />

<!-- Unite Gallery-->
<script type="text/javascript">
    $(document).ready(function(){
        $("#gallery").unitegallery({
            // http://unitegallery.net/index.php?page=tiles-justified-options
            gallery_theme: "tiles",
            tiles_type: "justified"
            // ,gallery_width:"75%"
        });
    });
</script>

<!-- MathJax: https://www.mathjax.org/ -->
<!-- Turn on equation numbering: http://docs.mathjax.org/en/latest/tex.html#automatic-equation-numbering -->
<script type="text/x-mathjax-config">
        MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<!-- Hypothes.is (https://web.hypothes.is/) -->

    <script src="https://hypothes.is/embed.js" async></script>

</head>


<body>

    <div class="header">
     <div class="container">
         <h1 class="logo"><a href="/">Dani's Braindump</a></h1>
         <nav class="nav-collapse">
             <ul class="noList">
                 
                 <li class="element first  ">
                     <a href="/index.html">Home</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/about">About</a>
                 </li> 
                 
                 <li class="element  current ">
                     <a href="/ml">Machine Learning</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/frenzy">Swiss Frenzy</a>
                 </li> 
                 
                 <li class="element   last">
                     <a href="/contact">Contact</a>
                 </li> 
                 
             </ul>
         </nav>
     </div>
 </div><!-- end .header -->


   <div class="content">
      <div class="container">
         <div class="post">
    

    <h1 class="postTitle">Deep Learning (3/5): Structuring ML projects</h1>

    
        <p class="meta"><span class="time">12</span> Minute Read</p>
    

    
        <p class="alert alert-primary alert-dismissible fade show" role="alert">
    This page uses <strong><a href="https://web.hypothes.is/" target="_blank">Hypothes.is</a></strong>. You can annotate or highlight text directly on this page by expanding the bar on the right. If you find any errors, typos or you think some explanation is not clear enough, please feel free to add a comment. This helps me improving the quality of this site. <strong>Thank you!</strong>
    <button type="button" class="close" data-dismiss="alert" aria-label="Close">
        <span aria-hidden="true">&times;</span>
    </button>
</p>
    

    
        <p style="text-align:center">

    <span class="badge badge-secondary">Orthogonalization</span>

    <span class="badge badge-secondary">F1-Score</span>

    <span class="badge badge-secondary">Precision</span>

    <span class="badge badge-secondary">Recall</span>

    <span class="badge badge-secondary">Satisficing And Optimizing Metrics</span>

    <span class="badge badge-secondary">Train/Dev/Test-Set Distributions</span>

    <span class="badge badge-secondary">Avoidable Bias</span>

    <span class="badge badge-secondary">Human Level Performance</span>

    <span class="badge badge-secondary">Bayes Optimal Error</span>

    <span class="badge badge-secondary">Error Analysis</span>

    <span class="badge badge-secondary">Label Cleaning</span>

    <span class="badge badge-secondary">Transfer Learning</span>

    <span class="badge badge-secondary">Multi-Task Learning</span>

    <span class="badge badge-secondary">E2E-Deep Learning</span>

</p>
    

    
        <p class="intro">
    <span class="dropcap">T</span>
    <p>his course focuses on conceptual aspects and workflow planning rather than introducing new algorihms or frameworks. The goal of this course is to equip you with knowledge you would otherwise have to earn through experience. Therefore, despite being the shortes of all in the DL specialization, this course can make a huge difference for you when you start out with your own project. In fact, it can save you from going in the wrong direction for months and then realizing your work was all for nothing. Due to the less technical nature of this course there are no quizzes or programming assignments. Instead you get to sit in a <em>“Machine Learning flight simulator”</em>, where you are presented with a real-world problem and then have to decide how to act next.</p>

</p>
    

    <div><h4 class="no_toc" id="table-of-contents">Table of Contents</h4>

<ul id="markdown-toc">
  <li><a href="#course-overview" id="markdown-toc-course-overview">Course overview</a></li>
  <li><a href="#ml-strategy" id="markdown-toc-ml-strategy">ML Strategy</a>    <ul>
      <li><a href="#orthogonalization" id="markdown-toc-orthogonalization">Orthogonalization</a></li>
      <li><a href="#setting-up-your-goal" id="markdown-toc-setting-up-your-goal">Setting up your goal</a></li>
      <li><a href="#traindevtest-set-distributions" id="markdown-toc-traindevtest-set-distributions">Train/Dev/Test set distributions</a>        <ul>
          <li><a href="#bias-and-variance-with-mismatched-data-distributions" id="markdown-toc-bias-and-variance-with-mismatched-data-distributions">Bias and variance with mismatched data distributions.</a></li>
        </ul>
      </li>
      <li><a href="#comparing-to-human-level-performance" id="markdown-toc-comparing-to-human-level-performance">Comparing to human-level performance</a></li>
    </ul>
  </li>
  <li><a href="#error-analysis" id="markdown-toc-error-analysis">Error analysis</a>    <ul>
      <li><a href="#cleaning-up-incorrectly-labelled-data" id="markdown-toc-cleaning-up-incorrectly-labelled-data">Cleaning up incorrectly labelled data</a></li>
      <li><a href="#build-quickly-then-iterate" id="markdown-toc-build-quickly-then-iterate">Build quickly, then iterate</a></li>
    </ul>
  </li>
  <li><a href="#transfer-learning" id="markdown-toc-transfer-learning">Transfer learning</a></li>
  <li><a href="#multi-task-learning" id="markdown-toc-multi-task-learning">Multi-task learning</a></li>
  <li><a href="#end-to-end-deep-learning" id="markdown-toc-end-to-end-deep-learning">End-to-end Deep Learning</a></li>
</ul>

<h2 id="course-overview">Course overview</h2>
<p>The <strong>first week</strong> focuses on setting up a strategy when working on a DL task. It also reflects on how to measure an algorithms performance and how to improve it.
The <strong>second week</strong> introduces common errors that can lead to poor performance. It also shows how to find those errors and how to deal with them.</p>

<h2 id="ml-strategy">ML Strategy</h2>
<p>There comes a point in every ML project where you have trained your Deep-NN and you are still not satisfied with its performance. You therefore want to improve it. You have learned a few methods to do this in <a href="/ml/deep-learning/2">part 2</a>:</p>

<ul>
  <li>Gather more training data</li>
  <li>try a different optimizer</li>
  <li>…</li>
</ul>

<p>Deciding on what action to take next is not trivial. However, where are a few strategies that can help choosing the measure that will produce the biggest performance gain.</p>

<h3 id="orthogonalization">Orthogonalization</h3>

<p>I have introduced the term <strong>orthogonalization</strong> in <a href="/ml/deep-learning/2">part 2</a> quickly. I am going to lay it out in more detail here.
Training a NN in ML usually involves the following steps:</p>

<ul>
  <li>Optimize the cost function on the training set</li>
  <li>Optimize the cost function on the dev set (validation set)</li>
  <li>Optimize the cost function on the test set</li>
  <li>Rely on the assumptions that a NN trained this way will generalize well on unseen (and unlabelled) data.</li>
</ul>

<p>An important principle when optimizting the parameters for the cost function is orthogonalization. This term generally states that a specific action should only affect one of the above steps, not several at the same points. Andrew uses an old TV as a metaphor for this. Such a TV usually had different knobs you could use: one for image height, one for image width, one for horiziontal translation, one for vertical translation and so on. You could fine-tune the image using all of these knobs, but a single knob would only affect one specific property of the image.</p>

<p>Simliarly we can fine-tune our NN on the individual steps mentionned above with a set of actions (“knobs”):</p>

<table>
  <thead>
    <tr>
      <th>Step/Problem</th>
      <th>Action</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>NN does not perform well on training set</td>
      <td>Try out bigger NN <br />try out different NN archtecture<br />try out a different optimizer (Momentum, RMSprop, Adam, …)<br />train longer (more iterations)</td>
    </tr>
    <tr>
      <td>NN does not perform well on dev set</td>
      <td>use regularization<br />use a bigger training set</td>
    </tr>
    <tr>
      <td>NN does not perform well on test set</td>
      <td>use a bigger dev-set</td>
    </tr>
    <tr>
      <td>NN does not generalize well for unseen instances</td>
      <td>use a different dev set (different probability distribution)<br />try out a different cost function</td>
    </tr>
  </tbody>
</table>

<h3 id="setting-up-your-goal">Setting up your goal</h3>

<p>In order to evaluate your model it is often useful to have a metric, that indicates the model’s performance with a single number. That way you can compare this metric before and after taking an action. The best known metric to do this is the <strong>F1-Score</strong> (<script type="math/tex">F</script>), which uses the sub-metrics <strong>Precision</strong> (<script type="math/tex">P</script>) and <strong>Recall</strong> (<script type="math/tex">R</script>).</p>

<script type="math/tex; mode=display">P=\frac{TP}{TP+FP} \\\\
R = \frac{TP}{TP+FN} \\\\
F = \frac{2}{\frac{1}{P} + \frac{1}{R} } = 2\cdot \frac{P\cdot R}{P+R}</script>

<p>An alternative for this metric would be to simply calculate the average error over all instances. When optimizing a NN you usually have several metrics that you want to fine-tune. When doing this, you typically distinguish two different types of metrics:</p>

<ul>
  <li><strong>Optimizing metric</strong>: The metric should produce an <em>optimal</em> value (e.g. the NN should have maximal accuracy)</li>
  <li><strong>Satisficing metric</strong>: The metric should produce an <em>acceptable</em> value (e.g. the NN should have a runtime that is feasibile for training)</li>
</ul>

<p>When fine-tuning your NN, it often makes sense to treat one of the metrics as optimizing and all the other as satisficing in order to reach your goal.</p>

<h3 id="traindevtest-set-distributions">Train/Dev/Test set distributions</h3>

<p>Carefully defining your training-, dev- and test-set can have a huge impact on your NN’s performance. It is crucial that the data in these sets all come from the same <strong>probability distribution</strong>. What I mean by this can be illustrated with an example: Suppose you’re training a NN that can classify pictures as cat-pictures or not. If your train your NN with training images of cats that are indoor (or even worse: only cats of a specific race or color), your NN will have a hard time classifying pictures of cats that were taken outdoors (or cats of different races or color).</p>

<p>Mismatched training and dev/test-sets often root in the nature of DL algorithms, which usually require a lot of labelled data. Such data must then be obtained from all available sources. This can become problematic, if for example you train a variant of the above cat classifier to recognize cats from small resolutions images of mobile phones. Representative training data might not be available in the necessary quantity. However, there are more than enough pictures of cats on the internet. But these are usually high-resolution images and hence come from a different distribution. You usually have two options dealing with such situations:</p>

<ul>
  <li><strong>Option 1</strong>: Integrate all pictures (high- and low-res) in one set, shuffle it adn the split into training-, dev- and test-set. This approach usually works out badly because the dev-set should set the goal for optimization and only a small part of the images in the dev-set actually come from the desired distribution (in this case low-res images)</li>
  <li><strong>Option 2</strong>: Use only low-res images for dev- and test-set. Put all high-res images into the training set and add the remaining low-res images.</li>
</ul>

<p>As mentionned, option 1 does usually not work very well. Option 2 has the disadvantage that the different sets have different distributions, but there are methods to handle that (see below)</p>

<p>As mentioned in <a href="/ml/deep-learning/1">part one</a>, a common split of labelled data into training-, dev- and test set was 60/20/20. However, with the availability of big data this has gradually shifted to the proportion of 98/1/1. Sometimes it may be OK to have no validation set at all. When doing this you should make sure not to use data from the test set to optimize the parameters because the test set should in any case only contain data the NN has never seen before.</p>

<h4 id="bias-and-variance-with-mismatched-data-distributions">Bias and variance with mismatched data distributions.</h4>

<p>If your train/dev/test sets end up having different distributions (e.g. from option 2 above) you can further split up the training set in the actual training data and a set we can call <em>train-dev-set</em> which has the same distribution as the training data. You can use this train-dev-set for validation and compare the error with the error on the real validation set to finid out whether you have a variance problem:</p>

<ul>
  <li>if the difference between the errors is big, you have a variance problem (i.e. the algorithm does not generalize well)</li>
  <li>if the difference between the errors is small, the differences can be attributed to the different distributions (data mismatch problem)</li>
</ul>

<p>You can of course also address the data mismatch problem by collecting more training data from the desired distribution (i.e. data like the one in the dev/test-set) or you can synthetisize data (data augmentation).</p>

<h3 id="comparing-to-human-level-performance">Comparing to human-level performance</h3>

<p>ML can improve very quickly in the beginning and surpass human-level performance at some point. For example contemporary face recognition algorithms are capable of identifying people with remarkable accuracy nowadays. I synchronize my photos with Google Photos, which finds faces of people on the photos and groups them into photos of the same people. I’m often surprised how well this works when sometimes even I as a human would not have found a particular face on a photo or would not be able to identify one particular face.</p>

<p>As long as an algorithm performs worse than a human it can be relatively easily be optimized by feeding it additional labelled data. However, after surpassing human-level performance it can become difficult to optimize it even further.</p>

<p>After an initial steep learning curve, the performance gain gradually flattens out and approximates an (unknown) value which is referred to as <strong>Bayes Optimal Error</strong> (BOE). This value defines the hypothetical best possible performance an algorithm can reach. It does not necessarily mean a 0% error rate! The BOE can be estimated for some ML problems (e.g. image classification) by comparing it to human-level performance. In these settings it can be assumed that the optimal error rate is close to the BOE. When training an algorithm one should consider this error rate.</p>

<p>The difference between the performance on the training set and the BOE is called <strong>avoidable bias</strong>. If the avoidable bias is big it should be reduced by additional training. In case the accuracy on the training set is already pretty close to the BOE the algorithm is already pretty well-trained. It can however still be improved by focussing on the error on the validation set (focus on variance).</p>

<p>In settings like above, comparing to human-level performance can help in deciding how useful a model is. As soon as a model surpasses human-level performance, it is impossible to determine how high the avoidable bias is (because we don’t know where the BOE will be). This is usually the case with structured data, where ML-algorithms are usually better than humans.</p>

<h2 id="error-analysis">Error analysis</h2>

<p>To reduce the error rate of an algorithm it is often useful to examine the instances more closely, where the algorithm did not perform well. If you for example train your cat-classifier you could inspect a sample of 100 images that were erroneously classified as cats. If it turns out that the larger part of these samples are dog pictures, this indicates that the model should primarily be trained with respect to dog pictures. In other words: Training the algorithm to distinguish better between cats and dogs will probably have the biggest impact on the error rate.</p>

<h3 id="cleaning-up-incorrectly-labelled-data">Cleaning up incorrectly labelled data</h3>

<p>Inspecting samples can generally help identifying problematic areas of an algorithm. Likewise, mislabeled training data can also be identified by using samples. Wrong labels in the training data are rarely a problem, as long as they are not systematic. However, ML algorithms are usually prone to systematically mislabelled training samples.
Fixing mislabelled training data is time consuming and only makes sense if the wrong labels are responsible for a big part of the errors. However, if you need to fix your labels you should also have a look at samples of correctly classified samples to see if not any of them are actually wrong.</p>

<h3 id="build-quickly-then-iterate">Build quickly, then iterate</h3>

<p>When starting out with an ML project there are usually a lot of directions to go in the beginning. It is therefore crucial to set up a first goal by defining a dev/test set and a metric to optimize. This helps to prioritize the next steps. After having a first goal you can optimize your algorithm towards it and then set up your next goal (rinse and repeat). This process helps you to streamline your actions towards your end goal and reach intermediate results more quickly.</p>

<h2 id="transfer-learning">Transfer learning</h2>

<p>When trainin data is scarce you can try to apply the results from one NN to another. To do this you can download a pre-trained NN and try to tune it into your desired direction. If for instance you train a classifier for X-ray images, you could download a pre-trained NN that performs well on photographic images and then optimize it for x-ray images. This is called <strong>transfer learning</strong>.</p>

<p>Transfer learning usually involves replacing the last layer of a NN and optimize only this. If you have more training data you can also replace/optimize the last few layers. This way you don’t need to optimize <em>all</em> the parameters of your NN and can focus on optimizing only the parameters of the replaced layers with your training data.</p>

<p>By replacing the last (few) layer(s) the previous layers can be considered <em>frozen</em>. A lot of DL frameworks support this by providing corresponding parameteres (e.g. <code class="highlighter-rouge">freeze=1</code> or <code class="highlighter-rouge">trainableParameter=0</code>.</p>

<p>Transfer learning makes sense if…</p>

<ul>
  <li>… there is a lot of training data for a general problem and only little data for a specific problem</li>
  <li>… a general problem has the same input data as a specific problem</li>
  <li>… low-level features of a general problem are relevant for high-level features of a specific problem</li>
</ul>

<h2 id="multi-task-learning">Multi-task learning</h2>
<p>A NN can be optimized for several targets. You can for example train a NN not only to recognize cars, but also people, signs and red lights (autonomous driving). This is called <strong>multi-task learning</strong>. In such settings, the label <script type="math/tex">y</script> is usually a vector and not a scalar. The set of labels <script type="math/tex">Y</script> is then consequently not a vector, but a <script type="math/tex">(k\times m)</script> matrix of <script type="math/tex">k</script> labels whereas not all labels need to be known (sparse matrix).</p>

<p>Multi-task learning makes sense if…</p>

<ul>
  <li>… the individual tasks can benefit from the same low-level features</li>
  <li>… the amount of training data per task is about the same</li>
  <li>… a single NN can be trained, which is big enough to learn all the tasks</li>
</ul>

<h2 id="end-to-end-deep-learning">End-to-end Deep Learning</h2>

<p>Several steps in a pipeline can be combined to a single NN. This is called <strong>End-to-end Deep Learning</strong> (E2E-DL). An example for such steps are (from speech recognition):</p>

<ul>
  <li>extraction of features from audio</li>
  <li>identification of single phonemes</li>
  <li>concatenation of phonemes to words</li>
  <li>…</li>
  <li>creation fo a transcript</li>
</ul>

<p>Such E2E-Settings usually require a lot more data than traditional approaches. For some tasks (like machine translation) however this is less of a problem, because data is available in sufficient quantities.</p>

<p>Advantages of E2E-DL are:</p>

<ul>
  <li>the training data really matters and the results don’t contain implicit human previous knowledge (“<em>lets the data speak</em>”)</li>
  <li>no time delay by manual design of intermediate components</li>
</ul>

<p>Disadvantages of E2E-DL are:</p>

<ul>
  <li>higher demand for labelled data</li>
  <li>potentially manually designed components that would be helpful are disregarded.</li>
</ul>
</div>
  
    
    <p id="disqus_thread"></p>
    <script>

        /**
         *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
         *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

        var disqus_config = function () {
            this.page.url = "https://tiefenauer.github.io";  // Replace PAGE_URL with your page's canonical URL variable
            this.page.identifier = "/ml/deep-learning/3"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };

        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://tiefenauer.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


</div>
      </div>
   </div><!-- end .content -->

   <div class="footer">
   <div class="container">
      <p class="copy">&copy; 2018 <a href="http://www.tiefenauer.info">Daniel Tiefenauer</a>
      <!-- Powered by <a href="http://jekyllrb.com">Jekyll</a> with adapted <a href="https://github.com/brianmaierjr/long-haul">Long Haul</a> Theme -->
      </p>

      <div class="footer-links"> 
         <ul class="noList"> 
            
            <li><a href="https://www.facebook.com/daniel.tiefenauer">
                  <svg id="facebook-square" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M82.667,1H17.335C8.351,1,1,8.351,1,17.336v65.329c0,8.99,7.351,16.335,16.334,16.335h65.332 C91.652,99.001,99,91.655,99,82.665V17.337C99,8.353,91.652,1.001,82.667,1L82.667,1z M84.318,50H68.375v42.875H50V50h-8.855V35.973 H50v-9.11c0-12.378,5.339-19.739,19.894-19.739h16.772V22.3H72.967c-4.066-0.007-4.57,2.12-4.57,6.078l-0.023,7.594H86.75 l-2.431,14.027V50z"></path>
                  </svg>
            </a></li>
            
            
            <li><a href="https://twitter.com/danitiefenauer">
                  <svg id="twitter" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M99.001,19.428c-3.606,1.608-7.48,2.695-11.547,3.184c4.15-2.503,7.338-6.466,8.841-11.189 c-3.885,2.318-8.187,4-12.768,4.908c-3.667-3.931-8.893-6.387-14.676-6.387c-11.104,0-20.107,9.054-20.107,20.223 c0,1.585,0.177,3.128,0.52,4.609c-16.71-0.845-31.525-8.895-41.442-21.131C6.092,16.633,5.1,20.107,5.1,23.813 c0,7.017,3.55,13.208,8.945,16.834c-3.296-0.104-6.397-1.014-9.106-2.529c-0.002,0.085-0.002,0.17-0.002,0.255 c0,9.799,6.931,17.972,16.129,19.831c-1.688,0.463-3.463,0.71-5.297,0.71c-1.296,0-2.555-0.127-3.783-0.363 c2.559,8.034,9.984,13.882,18.782,14.045c-6.881,5.424-15.551,8.657-24.971,8.657c-1.623,0-3.223-0.096-4.796-0.282 c8.898,5.738,19.467,9.087,30.82,9.087c36.982,0,57.206-30.817,57.206-57.543c0-0.877-0.02-1.748-0.059-2.617 C92.896,27.045,96.305,23.482,99.001,19.428z"></path>
                  </svg>
            </a></li>
            
            
            <li><a href="https://github.com/tiefenauer">
                  <svg id="github" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M50,1C22.938,1,1,22.938,1,50s21.938,49,49,49s49-21.938,49-49S77.062,1,50,1z M79.099,79.099 c-3.782,3.782-8.184,6.75-13.083,8.823c-1.245,0.526-2.509,0.989-3.79,1.387v-7.344c0-3.86-1.324-6.699-3.972-8.517 c1.659-0.16,3.182-0.383,4.57-0.67c1.388-0.287,2.855-0.702,4.402-1.245c1.547-0.543,2.935-1.189,4.163-1.938 c1.228-0.75,2.409-1.723,3.541-2.919s2.082-2.552,2.847-4.067s1.372-3.334,1.818-5.455c0.446-2.121,0.67-4.458,0.67-7.01 c0-4.945-1.611-9.155-4.833-12.633c1.467-3.828,1.308-7.991-0.478-12.489l-1.197-0.143c-0.829-0.096-2.321,0.255-4.474,1.053 c-2.153,0.798-4.57,2.105-7.249,3.924c-3.797-1.053-7.736-1.579-11.82-1.579c-4.115,0-8.039,0.526-11.772,1.579 c-1.69-1.149-3.294-2.097-4.809-2.847c-1.515-0.75-2.727-1.26-3.637-1.532c-0.909-0.271-1.754-0.439-2.536-0.503 c-0.782-0.064-1.284-0.079-1.507-0.048c-0.223,0.031-0.383,0.064-0.478,0.096c-1.787,4.53-1.946,8.694-0.478,12.489 c-3.222,3.477-4.833,7.688-4.833,12.633c0,2.552,0.223,4.889,0.67,7.01c0.447,2.121,1.053,3.94,1.818,5.455 c0.765,1.515,1.715,2.871,2.847,4.067s2.313,2.169,3.541,2.919c1.228,0.751,2.616,1.396,4.163,1.938 c1.547,0.543,3.014,0.957,4.402,1.245c1.388,0.287,2.911,0.511,4.57,0.67c-2.616,1.787-3.924,4.626-3.924,8.517v7.487 c-1.445-0.43-2.869-0.938-4.268-1.53c-4.899-2.073-9.301-5.041-13.083-8.823c-3.782-3.782-6.75-8.184-8.823-13.083 C9.934,60.948,8.847,55.56,8.847,50s1.087-10.948,3.231-16.016c2.073-4.899,5.041-9.301,8.823-13.083s8.184-6.75,13.083-8.823 C39.052,9.934,44.44,8.847,50,8.847s10.948,1.087,16.016,3.231c4.9,2.073,9.301,5.041,13.083,8.823 c3.782,3.782,6.75,8.184,8.823,13.083c2.143,5.069,3.23,10.457,3.23,16.016s-1.087,10.948-3.231,16.016 C85.848,70.915,82.88,75.317,79.099,79.099L79.099,79.099z"></path>
                  </svg>
            </a></li>
             
            
            <li><a href="https://www.linkedin.com/in/danieltiefenauer">
                <svg id="linkedin" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(2.0)" d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/>
                </svg>
            </a></li>
             
            
            <li><a href="https://www.xing.com/profile/Daniel_Tiefenauer/cv">
                <svg id="xing" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(2.0)" d="M14.887 24l-5.324-9.667 8.07-14.333h4.933l-8.069 14.333 5.27 9.667h-4.88zm-7.291-19h-4.939l2.768 4.744-4.115 7.256h4.914l4.117-7.271-2.745-4.729z"/>
                </svg>
            </a></li>
                         
            
            <li><a href="mailto:daniel@tiefenauer.info">
                  <svg id="mail" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M50,1C22.938,1,1,22.938,1,50s21.938,49,49,49s49-21.938,49-49S77.062,1,50,1z M25.5,25.5h49 c0.874,0,1.723,0.188,2.502,0.542L50,57.544L22.998,26.041C23.777,25.687,24.626,25.499,25.5,25.5L25.5,25.5z M19.375,68.375v-36.75 c0-0.128,0.005-0.256,0.014-0.383l17.96,20.953L19.587,69.958C19.448,69.447,19.376,68.916,19.375,68.375L19.375,68.375z M74.5,74.5 h-49c-0.541,0-1.072-0.073-1.583-0.212l17.429-17.429L50,66.956l8.653-10.096l17.429,17.429C75.572,74.427,75.041,74.5,74.5,74.5 L74.5,74.5z M80.625,68.375c0,0.541-0.073,1.072-0.211,1.583L62.652,52.195l17.96-20.953c0.008,0.127,0.014,0.255,0.014,0.383 L80.625,68.375L80.625,68.375z"></path>
                  </svg>
            </a></li>
            
         </ul>
      </div>
   </div>
</div><!-- end .footer -->


   <!-- Bootstrap scripts-->
<script>
    $('.alert').alert()
</script>

</body>

</html>
